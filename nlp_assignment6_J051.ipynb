{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otdNFdfrzrp5"
   },
   "source": [
    "##**Semantic Search for Quora Duplicate Questions using Bi-Encoders and Cross-Encoders**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1AkipzgVzxda"
   },
   "source": [
    "\n",
    "\n",
    "This project implements a **semantic similarity pipeline** to detect duplicate questions on Quora using **state-of-the-art transformer models**. The workflow includes:\n",
    "\n",
    "1. **Data Preparation:**\n",
    "\n",
    "   * Load the Quora Question Pairs dataset.\n",
    "   * Sample a **smaller subset** (50k rows) for CPU-friendly experimentation.\n",
    "   * Split into **train, validation, and test sets** (test set is constant for all experiments).\n",
    "\n",
    "2. **Benchmarking:**\n",
    "\n",
    "   * Evaluate a **pre-trained Sentence-BERT model** (`all-MiniLM-L6-v2`) using cosine similarity.\n",
    "\n",
    "3. **Model Training:**\n",
    "\n",
    "   * Train **Bi-Encoder models** using three loss functions:\n",
    "\n",
    "     * **Cosine Similarity Loss**\n",
    "     * **Contrastive Loss**\n",
    "     * **Multiple Negative Ranking Loss (MNR)**\n",
    "   * Train a **Cross-Encoder model** for pairwise classification.\n",
    "\n",
    "4. **Evaluation:**\n",
    "\n",
    "   * Evaluate all models on the **same test set** using **F1-Score**.\n",
    "   * Use **thresholding** on similarity scores for Bi-Encoders and predicted probabilities for Cross-Encoder.\n",
    "\n",
    "5. **Visualization:**\n",
    "\n",
    "   * **F1-Score comparison bar chart** across all models.\n",
    "   * **Confusion matrix** for the best-performing model.\n",
    "   * **Score distribution plots** to visualize separation between duplicate and non-duplicate pairs.\n",
    "\n",
    "**Purpose:**\n",
    "The notebook provides a **fast, modular, and interpretable pipeline** to compare different semantic search approaches for question duplication detection on CPU, while allowing easy scaling to GPU for larger experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy scikit-learn sentence-transformers transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers transformers scikit-learn torch tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load CSV with proper separator\n",
    "df = pd.read_csv(\"/content/train.csv\")  # default sep=','\n",
    "\n",
    "# Keep only relevant columns\n",
    "df = df[['question1', 'question2', 'is_duplicate']].dropna()\n",
    "\n",
    "# Sample smaller subset for CPU-friendly runs\n",
    "df_sample = df.sample(n=50000, random_state=42)\n",
    "\n",
    "# Split into train, val, test\n",
    "train_df, test_df = train_test_split(df_sample, test_size=0.1, random_state=42, stratify=df_sample['is_duplicate'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42, stratify=train_df['is_duplicate'])\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "test_pairs = list(zip(test_df['question1'].tolist(), test_df['question2'].tolist()))\n",
    "test_labels = test_df['is_duplicate'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # small & fast\n",
    "\n",
    "# Encode test questions\n",
    "q1_emb = model.encode(test_df['question1'].tolist(), convert_to_tensor=True)\n",
    "q2_emb = model.encode(test_df['question2'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "# Cosine similarity\n",
    "cos_scores = util.cos_sim(q1_emb, q2_emb).diagonal().cpu().numpy()\n",
    "preds = (cos_scores > 0.7).astype(int)\n",
    "\n",
    "print(\"F1-Score (Benchmark):\", f1_score(test_labels, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable W&B logging completely\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Imports\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Helper function to train bi-encoder\n",
    "def train_bi_encoder(train_data, val_data, loss_type='cosine', model_name='all-MiniLM-L6-v2', epochs=1):\n",
    "    # Prepare training examples\n",
    "    train_examples = [InputExample(texts=[q1, q2], label=float(label))\n",
    "                      for q1, q2, label in zip(train_data['question1'], train_data['question2'], train_data['is_duplicate'])]\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)  # CPU-friendly batch size\n",
    "\n",
    "    # Select loss\n",
    "    if loss_type=='cosine':\n",
    "        loss = losses.CosineSimilarityLoss(model=SentenceTransformer(model_name))\n",
    "    elif loss_type=='contrastive':\n",
    "        loss = losses.ContrastiveLoss(model=SentenceTransformer(model_name))\n",
    "    elif loss_type=='mnr':\n",
    "        loss = losses.MultipleNegativesRankingLoss(model=SentenceTransformer(model_name))\n",
    "\n",
    "    # Validation evaluator (optional, for monitoring)\n",
    "    val_examples = [InputExample(texts=[q1, q2], label=float(label))\n",
    "                    for q1, q2, label in zip(val_data['question1'], val_data['question2'], val_data['is_duplicate'])]\n",
    "    evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(val_examples, name='val-eval')\n",
    "\n",
    "    # Train\n",
    "    model = loss.model\n",
    "    model.fit(\n",
    "        train_objectives=[(train_dataloader, loss)],\n",
    "        epochs=epochs,\n",
    "        evaluator=evaluator,\n",
    "        evaluation_steps=500,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-encoder with Cosine Similarity Loss\n",
    "bi_cos_model = train_bi_encoder(train_df, val_df, loss_type='cosine', epochs=1)\n",
    "\n",
    "# Bi-encoder with Contrastive Loss\n",
    "bi_contrastive_model = train_bi_encoder(train_df, val_df, loss_type='contrastive', epochs=1)\n",
    "\n",
    "# Bi-encoder with Multiple Negative Ranking Loss\n",
    "bi_mnr_model = train_bi_encoder(train_df, val_df, loss_type='mnr', epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "cross_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2', num_labels=1)\n",
    "\n",
    "# Prepare training examples for CrossEncoder\n",
    "train_samples = [InputExample(texts=[q1, q2], label=float(label))\n",
    "                 for q1, q2, label in zip(train_df['question1'], train_df['question2'], train_df['is_duplicate'])]\n",
    "\n",
    "train_dataloader = DataLoader(train_samples, batch_size=16, shuffle=True)\n",
    "\n",
    "# Quick CPU-friendly training (1 epoch)\n",
    "cross_model.fit(train_dataloader, epochs=1, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util\n",
    "\n",
    "def evaluate_bi_model(model, test_df, threshold=0.7):\n",
    "    q1_emb = model.encode(test_df['question1'].tolist(), convert_to_tensor=True)\n",
    "    q2_emb = model.encode(test_df['question2'].tolist(), convert_to_tensor=True)\n",
    "    cos_scores = util.cos_sim(q1_emb, q2_emb).diagonal().cpu().numpy()\n",
    "    preds = (cos_scores > threshold).astype(int)\n",
    "    return f1_score(test_labels, preds)\n",
    "\n",
    "def evaluate_cross_model(model, test_df, threshold=0.5):\n",
    "    scores = model.predict(list(zip(test_df['question1'], test_df['question2'])))\n",
    "    preds = (scores > threshold).astype(int)\n",
    "    return f1_score(test_labels, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1-Score Bi-Cosine:\", evaluate_bi_model(bi_cos_model, test_df))\n",
    "print(\"F1-Score Bi-Contrastive:\", evaluate_bi_model(bi_contrastive_model, test_df))\n",
    "print(\"F1-Score Bi-MNR:\", evaluate_bi_model(bi_mnr_model, test_df))\n",
    "print(\"F1-Score Cross-Encoder:\", evaluate_cross_model(cross_model, test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Collect F1-scores\n",
    "f1_scores = {\n",
    "    \"Bi-Cosine\": evaluate_bi_model(bi_cos_model, test_df),\n",
    "    \"Bi-Contrastive\": evaluate_bi_model(bi_contrastive_model, test_df),\n",
    "    \"Bi-MNR\": evaluate_bi_model(bi_mnr_model, test_df),\n",
    "    \"Cross-Encoder\": evaluate_cross_model(cross_model, test_df)\n",
    "}\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=list(f1_scores.keys()), y=list(f1_scores.values()), palette=\"viridis\")\n",
    "plt.title(\"F1-Score Comparison of Models\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.ylim(0,1)\n",
    "for i, v in enumerate(f1_scores.values()):\n",
    "    plt.text(i, v+0.02, f\"{v:.2f}\", ha='center', fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df['is_duplicate'].dtype)\n",
    "print(train_df['is_duplicate'].unique())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
